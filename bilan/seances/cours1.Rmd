---
title: "Classification Non Supevisée , cours 1"
author: "Anna Mathieu"
date: "`r Sys.Date()`"
output: html_document
---

## Récupération des données 

```{r}
library(FactoMineR)
data("decathlon")
data <- decathlon
data <- data[,1:10]

summary(data) 
```


Calcul du vecteur des moyennes par calcul matriciel 

```{r}
moy_matr <- matrix(1, nrow = nrow(data), ncol = ncol(data) ) # construction de la matrice des moyennes de dimension n (41) x p (10)

# transforme data en matrice 
data <- as.matrix(data)

# création de la matrice NxP des moyennes 
for (i in 1:nrow(data)) {
  moy_col <- colMeans(data) #  récupération des moyennes par colonne de data 
  moy_matr[i,] <- moy_col   #  chaque colonne p(i) contient la moyenne de la colonne  i 
}

# Création de la matrice X centrée => X_Centrée = X (=data) - X_moyenne (=moy_matr)
X_centree = data - moy_matr

# test : data[1,1] - 11

X_centree # dim N * P 
```

Calcul de la Matrice des Variances covariance X'X 
```{r}
# Initialisation de la matrice des var covariance : de dim p x p 
varcov_matr <- matrix(1, nrow = ncol(data), ncol = ncol(data))

get.covariance <- function (x1, x2, X) {
  # x1: variable 1 (n° col de X)
  # x2 : variable 2 (n° de col de X)
  # X : matrice centrée 
  
  cov = 0
  sum = 0

  for (i in 1:nrow(X)) {
    sum = sum + (X[i,x1] * X[i,x2])
    # print(sum)
  }
  
  cov = sum/(nrow(X)-1) 
  return(cov)
}
```

#######################################################
test de la formule 

```{r}
# Test de la formule : avec cov(X1,X1)
res <- get.covariance(x1 = 1, x2 = 1, X = X_centree)
res # 0.0691811

# variance de la variable "100m" 
var(X_centree[,1]) # 0.0691811
cov(X_centree[,1], X_centree[,1]) # 0.0691811



# Test de la formule avec cov(X1,X2)
res <- get.covariance(x1 = 1, x2 = 2, X_centree)
res # -0.0498225

cov(X_centree[,1], X_centree[,2]) # [1] -0.0498225
```
#######################################################

```{r}
# Remplissage de la matrice 

for (i in 1:ncol(X_centree)) {
  for(j in 1:ncol(X_centree)){
    
    varcov_matr[i,j] <- get.covariance(x1 = i, x2 = j, X_centree)
  }
}

dim(varcov_matr)

varcov_matr

```


<!-- Pondération de la matrice centrée par la racine carrée de la diagonale de la matrice de variance - covariance  -->

On a obtenu la matrice des covariances, qui contient dans sa trace (diagonale), les variances des variables 1 à 10. 

On va calculer à partir de cette matrice la matrice des r (coefficients de corrélation de Pearson) 
par la formule : 

p(x,y) = cov / (sqrt(x) * sqrt(y))

```{r}
# Calcul de la matrice des r 

coeff_cor <- matrix(0, nrow = 10, ncol = 10)

for (i in 1:ncol(varcov_matr)) {
  for (j in 1:ncol(varcov_matr)) {
    

  
    coeff_cor[i,j] <- varcov_matr[i,j] / (sqrt(varcov_matr[i,i]*varcov_matr[j,j]))

    
  }
}
coeff_cor

# il y a bien des 1 en diagonales : coeff de corrélation de 1 entre une variable et elle meme 

# test cor(x1,x2)
# cor(X_centree[,1], X_centree[,2]) 

```

Calcul de la matrice des r² : Carré de la matrice 'coeff_cor' 
```{r}
coeff_cor <- coeff_cor^2
```

Calcul de la matrice de distance: (1 - r²)
```{r}
dist_matr <- 1-coeff_cor
dist_matr
```


Par calcul matriciel, nous avons donc pu calculer la matrice des distances, correspondant à la matrice des 1-r² (r² = coefficients de corrélation)

Deux variables sont d'autant plus proches que leurs coefficients de distances sont proches. Deux variables identiques ont une corrélation de 1, et sont donc complètement confondues, il y a entre elles une distance nulle. 


## Clustering des variables 
```{r}
# on change le nom des cols et des rows 
names <- names(decathlon)[1:10]
colnames(dist_matr)<- names
rownames(dist_matr)<- names
```

PCA de la matrice de distance
```{r}
res.pca <- PCA(dist_matr)
```
Avec la PCA sur la matrice des distances entre les variables du jeu de données (interprétées comme des individus), on peut voir qu'il y a 3 clusters distincts de variables. On peut réaliser une classification ascendante hierarchique (HCPC) à partir afin de séparer les variables en 3 clusters.

```{r}
HCPC(res.pca, nb.clust = 3)
```

Les clusters identifiés sont :
- 400 m, long jump, 110 m hurdle [110 m haies], 100 m
- high jump [saut en hauteur], discus [lancer de disque], shot put [lancer de poids]
- 1500 m, pole vault [saut à la perche], javeline [lancer de javelot]

Interprétation des clusters : 
Les clusters regroupent des variables (épreuves de décathlon) qui se ressemblent, c'est-à-dire pour lesquelles les mêmes individus obtiennent des résultats similaires. Les individus réussissent similairement sur des épreuves similaires pour leur profil sportif, ce qui permet de regrouper les épreuves ensemble par similarité entre elles.

Le cluster 1 regroupe les épreuves de 400 m, saut en longueur, 100 m et 110 m haies. Ces épreuves sont des épreuves de vitesse et ce qui peuvent les rassembler ce sont qu'elles sont bien réussies par des sportifs vifs, impulsifs, ce sont des épreuves de vitesse / explosivité, car elles requièrent une vitesse explosive et une puissance anaérobie.

Le cluster 2 regroupe les épreuves de saut en hauteur, lancer de disque, lancer de poids. Ce sont des épreuves qui nécessitent de la force explosive, de la puissance du haut du corps et de la coordination technique.

Le cluster 3 regroupe les épreuves de 1500 m, de saut à la perche et de lancer de javelot. Le 1500 m est une épreuve d'endurance et 2 autres sont des épreuves qui requièrent une technique complexe, de la coordination et une certaine souplesse. Ce cluster regroupe des épreuves 'atypiques' du décathlon, la perche et le javelot faisant appel à des compétences très spécifiques. Ce cluster peut donc regrouper des sportifs au profil plus complet. 






